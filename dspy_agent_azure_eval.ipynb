{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ff02b0",
   "metadata": {},
   "source": [
    "# DSPy Agent Example with Azure OpenAI and Azure Evaluation SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d485a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import dspy\n",
    "import ujson\n",
    "import random\n",
    "import dspy.evaluate\n",
    "import dspy.retrievers\n",
    "import dspy.datasets\n",
    "from datasets import load_dataset\n",
    "from azure.ai.evaluation import AzureOpenAIModelConfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f6330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223a55c4",
   "metadata": {},
   "source": [
    "## Setup Tracing with MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b03b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"DSPy-Azure-Eval-Example\")\n",
    "\n",
    "# Enable tracing.\n",
    "mlflow.dspy.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd41816",
   "metadata": {},
   "source": [
    "## Setup LM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bb714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "gpt41 = dspy.LM(\n",
    "    model=f\"azure/gpt-4.1-2\",\n",
    "    base_url=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_ad_token_provider=token_provider,\n",
    ")\n",
    "\n",
    "gpt4omini=dspy.LM(\n",
    "    model=f\"azure/gpt-4o-mini\",\n",
    "    base_url=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_ad_token_provider=token_provider,\n",
    ")\n",
    "\n",
    "dspy.configure(lm=gpt4omini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8066f626",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt41(\"Say hello to the world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a815e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4omini(\"Say hello to the world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4843cb5",
   "metadata": {},
   "source": [
    "## Load HoVer multi-hop QA datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eec26f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HoVer dataset using parquet files (avoiding deprecated script)\n",
    "from datasets import load_dataset\n",
    "\n",
    "try:\n",
    "    # Try loading using parquet files which should be available\n",
    "    dataset = load_dataset(\"parquet\", data_files={\n",
    "        \"train\": \"hf://datasets/hover-nlp/hover/train-00000-of-00001.parquet\"\n",
    "    })\n",
    "    hover_train = dataset[\"train\"]\n",
    "except:\n",
    "    # Fallback: Load using the dataset name with revision\n",
    "    dataset = load_dataset(\"hover-nlp/hover\", revision=\"refs/convert/parquet\")\n",
    "    hover_train = dataset[\"train\"]\n",
    "\n",
    "# Convert to DSPy examples\n",
    "hover = []\n",
    "hpqa_ids = set()\n",
    "\n",
    "for x in hover_train:\n",
    "    if x[\"num_hops\"] == 3 and x[\"hpqa_id\"] not in hpqa_ids:\n",
    "        hpqa_ids.add(x[\"hpqa_id\"])\n",
    "        titles = list(set([y[\"key\"] for y in x[\"supporting_facts\"]]))\n",
    "        hover.append(\n",
    "            dspy.Example(claim=x[\"claim\"], titles=titles).with_inputs(\"claim\")\n",
    "        )\n",
    "\n",
    "random.Random(0).shuffle(hover)\n",
    "trainset, devset, testset = hover[:100], hover[100:200], hover[650:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8c2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainset), len(devset), len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b699da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df25f4f",
   "metadata": {},
   "source": [
    "## Tools for agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0b9d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCS = {}\n",
    "\n",
    "def search(query: str, k: int) -> list[str]:\n",
    "    results = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')(query, k=k)\n",
    "    results = [x['text'] for x in results]\n",
    "\n",
    "    for result in results:\n",
    "        title, text = result.split(\" | \", 1)\n",
    "        DOCS[title] = text\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae24f221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_wikipedia(query: str) -> list[str]:\n",
    "    \"\"\"Returns top-5 results and then the titles of the top-5 to top-30 results.\"\"\"\n",
    "\n",
    "    topK = search(query, 30)\n",
    "    titles, topK = [f\"`{x.split(' | ')[0]}`\" for x in topK[5:30]], topK[:5]\n",
    "    return topK + [f\"Other retrieved pages have titles: {', '.join(titles)}.\"]\n",
    "\n",
    "def lookup_wikipedia(title: str) -> str:\n",
    "    \"\"\"Returns the text of the Wikipedia page, if it exists.\"\"\"\n",
    "\n",
    "    if title in DOCS:\n",
    "        return DOCS[title]\n",
    "\n",
    "    results = [x for x in search(title, 10) if x.startswith(title + \" | \")]\n",
    "    if not results:\n",
    "        return f\"No Wikipedia page found for title: {title}\"\n",
    "    return results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74ebb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_wikipedia(\"Albert Einstein\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26299f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_wikipedia(\"Albert Einstein\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f1c2b7",
   "metadata": {},
   "source": [
    "## Define DSPy agent using `dspy.ReAct`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dd7e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"Find all Wikipedia titles relevant to verifying (or refuting) the claim.\"\n",
    "signature = dspy.Signature(\"claim -> titles: list[str]\", instructions)\n",
    "react = dspy.ReAct(signature, tools=[search_wikipedia, lookup_wikipedia], max_iters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037be09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "react(claim=\"David Gregory was born in 1625.\").titles[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5324a0",
   "metadata": {},
   "source": [
    "## Evaluate the agent using metrics from Azure Evaluation SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84c52e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import RetrievalEvaluator\n",
    "from azure.ai.evaluation import AzureOpenAIModelConfiguration\n",
    "\n",
    "class Relevance(dspy.Module):\n",
    "    def __init__(self, model_config, threshold=3):\n",
    "        self.relevance = RetrievalEvaluator(model_config=model_config, threshold=threshold)\n",
    "\n",
    "    def forward(self, example, pred, trace=None):\n",
    "        gold_titles = example.titles\n",
    "        claim = example.claim\n",
    "\n",
    "        titles = pred.titles[:5]\n",
    "        context = \"\\n\\n\".join([lookup_wikipedia(title) for title in titles])\n",
    "        scores = self.relevance(\n",
    "            query=claim,\n",
    "            context=context,\n",
    "        )\n",
    "        return scores[\"retrieval\"]\n",
    "    \n",
    "relevance = Relevance(\n",
    "    model_config=AzureOpenAIModelConfiguration(\n",
    "        azure_deployment=\"gpt-4.1-mini\",\n",
    "        azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "        api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    ),\n",
    "    threshold=3\n",
    ")\n",
    "\n",
    "evaluate = dspy.Evaluate(devset=devset, metric=relevance, num_threads=16, display_progress=True, display_table=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bfaa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = react(**devset[0].inputs())\n",
    "\n",
    "score = relevance(devset[0], pred)\n",
    "\n",
    "print(f\"Relevance score for the first example: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb71d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper to bypass exceptions during evaluation.\n",
    "def safe_react(claim: str):\n",
    "    try:\n",
    "        return react(claim=claim)\n",
    "    except Exception as e:\n",
    "        return dspy.Prediction(titles=[])\n",
    "\n",
    "evaluate(safe_react)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f5343b",
   "metadata": {},
   "source": [
    "## Optimize the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43213fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(teacher_settings=dict(lm=gpt41), prompt_model=gpt41, max_errors=999)\n",
    "\n",
    "tp = dspy.MIPROv2(metric=relevance, auto=\"medium\", num_threads=16, **kwargs)\n",
    "optimized_react = tp.compile(react, trainset=trainset, max_bootstrapped_demos=3, max_labeled_demos=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998ae6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_react(claim=\"The author of the 1960s unproduced script written for The Beatles, Up Against It, and Bernard-Marie Koltès are both playwrights.\").titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaeaaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_react.save(\"optimized_react.json\")\n",
    "\n",
    "loaded_react = dspy.ReAct(\"claim -> titles: list[str]\", tools=[search_wikipedia, lookup_wikipedia], max_iters=20)\n",
    "loaded_react.load(\"optimized_react.json\")\n",
    "\n",
    "loaded_react(claim=\"The author of the 1960s unproduced script written for The Beatles, Up Against It, and Bernard-Marie Koltès are both playwrights.\").titles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspy-azure-eval-example",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
